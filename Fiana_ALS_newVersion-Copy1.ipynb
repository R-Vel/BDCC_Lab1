{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f01185-3744-40aa-a125-7288504a5de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:06:12.386094Z",
     "iopub.status.busy": "2025-11-10T17:06:12.385500Z",
     "iopub.status.idle": "2025-11-10T17:06:22.721006Z",
     "shell.execute_reply": "2025-11-10T17:06:22.720037Z",
     "shell.execute_reply.started": "2025-11-10T17:06:12.386026Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17daf6c-be8a-4f96-a3f4-3cf2ca44c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./als_spark_checkpoints\"\n",
    "\n",
    "# Check if folder exists\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)   # Create folder\n",
    "    print(f\"Folder created: {folder_path}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560032f5-5b1a-4951-bced-bb25014be8a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:07:13.494462Z",
     "iopub.status.busy": "2025-11-10T17:07:13.493341Z",
     "iopub.status.idle": "2025-11-10T17:07:19.536683Z",
     "shell.execute_reply": "2025-11-10T17:07:19.534704Z",
     "shell.execute_reply.started": "2025-11-10T17:07:13.494399Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "     .builder\n",
    "     .master('local[*]') # tells you master is 1 laptop using all 4 executors\n",
    "     .config(\"spark.driver.memory\", \"8g\")\n",
    "     .config(\"spark.executor.memory\", \"8g\")\n",
    "     .config(\"spark.sql.shuffle.partitions\", \"8\")  # reduce for local\n",
    "     .getOrCreate()) # make new or get latest session\n",
    "\n",
    "spark.sparkContext.setCheckpointDir(\"./als_spark_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91af199-9145-4e22-bcc6-ea0fad56df3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:07:21.850744Z",
     "iopub.status.busy": "2025-11-10T17:07:21.849110Z",
     "iopub.status.idle": "2025-11-10T17:07:25.132274Z",
     "shell.execute_reply": "2025-11-10T17:07:25.130554Z",
     "shell.execute_reply.started": "2025-11-10T17:07:21.850668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read board game geek file on spark\n",
    "schema = \"\"\"\n",
    "_c0 INT,\n",
    "user STRING,\n",
    "rating FLOAT,\n",
    "comment STRING,\n",
    "id INT, \n",
    "name STRING\n",
    "\"\"\"\n",
    "# Fix quote handling for comments column \n",
    "df_spark = spark.read.csv(\n",
    "    \"/mnt/data/public/bgg/bgg-19m-reviews.csv\",\n",
    "    sep=',', header=True,\n",
    "    schema=schema,\n",
    "    multiLine=True,\n",
    "    quote='\"',\n",
    "    escape='\"')\n",
    "df_spark = df_spark.drop(\"_c0\", \"comment\", \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b8befb-56a1-4115-8087-191e58c653c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:07:25.135451Z",
     "iopub.status.busy": "2025-11-10T17:07:25.134874Z",
     "iopub.status.idle": "2025-11-10T17:08:00.477057Z",
     "shell.execute_reply": "2025-11-10T17:08:00.476013Z",
     "shell.execute_reply.started": "2025-11-10T17:07:25.135400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map user name to integer\n",
    "user_indexer = StringIndexer(inputCol=\"user\", outputCol=\"user_id\")\n",
    "df_spark_indexed = user_indexer.fit(df_spark).transform(df_spark)\n",
    "\n",
    "# Save Spark DF mapping of user to User ID\n",
    "user_mapping = df_indexed.select(\"user\", \"userId\").distinct()\n",
    "df_spark_indexed = df_spark_indexed.drop(\"user\")\n",
    "\n",
    "# Change item column name for unformity\n",
    "df_spark_indexed = df_spark_indexed.withColumnRenamed(\"id\", \"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc361b6b-b718-42f8-96b2-9e7666dd1fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:08:00.477883Z",
     "iopub.status.busy": "2025-11-10T17:08:00.477659Z",
     "iopub.status.idle": "2025-11-10T17:08:02.282305Z",
     "shell.execute_reply": "2025-11-10T17:08:02.281232Z",
     "shell.execute_reply.started": "2025-11-10T17:08:00.477864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+\n",
      "|rating|item_id| user_id|\n",
      "+------+-------+--------+\n",
      "|  10.0|  30549|   201.0|\n",
      "|  10.0|  30549|  6591.0|\n",
      "|  10.0|  30549|   631.0|\n",
      "|  10.0|  30549|  1705.0|\n",
      "|  10.0|  30549|  5796.0|\n",
      "|  10.0|  30549|    78.0|\n",
      "|  10.0|  30549|393225.0|\n",
      "|  10.0|  30549|233206.0|\n",
      "|  10.0|  30549| 22517.0|\n",
      "|  10.0|  30549| 87298.0|\n",
      "+------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_indexed.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4fe7ae-e982-4e95-a7e5-cb6f1fce9503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:08:02.283834Z",
     "iopub.status.busy": "2025-11-10T17:08:02.283608Z",
     "iopub.status.idle": "2025-11-10T17:08:23.297078Z",
     "shell.execute_reply": "2025-11-10T17:08:23.295155Z",
     "shell.execute_reply.started": "2025-11-10T17:08:02.283815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+\n",
      "|rating|item_id|user_id|\n",
      "+------+-------+-------+\n",
      "|     0|      0|      0|\n",
      "+------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count nulls per column\n",
    "null_counts = df_spark_indexed.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_spark_indexed.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bfe0956-aca8-4659-a0b5-adcba5f2e00f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:08:23.299489Z",
     "iopub.status.busy": "2025-11-10T17:08:23.298860Z",
     "iopub.status.idle": "2025-11-10T17:08:23.309258Z",
     "shell.execute_reply": "2025-11-10T17:08:23.307723Z",
     "shell.execute_reply.started": "2025-11-10T17:08:23.299433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:/home2/bsdsba2027/rvelasco/BDCC Labs/BDCC_Lab1/als_spark_checkpoints/cd532ad3-973f-4be8-acc1-64f92a7834cb\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext.getCheckpointDir())  # checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3650a1a7-d611-4738-8a41-3806e6c1fa43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:08:36.044686Z",
     "iopub.status.busy": "2025-11-10T17:08:36.043978Z",
     "iopub.status.idle": "2025-11-10T17:11:39.570471Z",
     "shell.execute_reply": "2025-11-10T17:11:39.568800Z",
     "shell.execute_reply.started": "2025-11-10T17:08:36.044628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train an ALS model\n",
    "train, test = df_spark_indexed.randomSplit([0.8, 0.2])\n",
    "als = ALS(rank=2, maxIter=5, \n",
    "          userCol=\"user_id\", itemCol='item_id', \n",
    "          ratingCol=\"rating\", coldStartStrategy='drop',\n",
    "          checkpointInterval=10  # Saves to disk after n iterations\n",
    "         )\n",
    "als_model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5a06e0-a970-4c9d-adda-c17fabbbdf9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:11:53.349976Z",
     "iopub.status.busy": "2025-11-10T17:11:53.349273Z",
     "iopub.status.idle": "2025-11-10T17:12:55.850624Z",
     "shell.execute_reply": "2025-11-10T17:12:55.849066Z",
     "shell.execute_reply.started": "2025-11-10T17:11:53.349918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error:1.2419596757757039\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = als_model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error:\" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00709ded-1a7b-4852-b38d-0715f94243c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:14:25.630205Z",
     "iopub.status.busy": "2025-11-10T17:14:25.629455Z",
     "iopub.status.idle": "2025-11-10T17:14:25.937138Z",
     "shell.execute_reply": "2025-11-10T17:14:25.936134Z",
     "shell.execute_reply.started": "2025-11-10T17:14:25.630145Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m movieRecs \u001b[38;5;241m=\u001b[39m als_model\u001b[38;5;241m.\u001b[39mrecommendForAllItems(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Generate top 10 movie recommendations for a specified set of users\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m users \u001b[38;5;241m=\u001b[39m \u001b[43mratings\u001b[49m\u001b[38;5;241m.\u001b[39mselect(als\u001b[38;5;241m.\u001b[39mgetUserCol())\u001b[38;5;241m.\u001b[39mdistinct()\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      8\u001b[0m userSubsetRecs \u001b[38;5;241m=\u001b[39m als_model\u001b[38;5;241m.\u001b[39mrecommendForUserSubset(users, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Generate top 10 user recommendations for a specified set of movies\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ratings' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = als_model.recommendForAllUsers(10)\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = als_model.recommendForAllItems(10)\n",
    "\n",
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = als_model.recommendForUserSubset(users, 10)\n",
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "movieSubSetRecs = als_model.recommendForItemSubset(movies, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1486d0ac-1e4f-4482-ad24-a2dee26c5066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:15:31.451138Z",
     "iopub.status.busy": "2025-11-10T17:15:31.450410Z",
     "iopub.status.idle": "2025-11-10T17:18:06.680040Z",
     "shell.execute_reply": "2025-11-10T17:18:06.679187Z",
     "shell.execute_reply.started": "2025-11-10T17:15:31.451077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>[(149705, 8.133953094482422), (254632, 8.13036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>[(345976, 7.779404163360596), (63170, 7.649724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>[(345976, 8.195059776306152), (277538, 8.04972...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                    recommendations\n",
       "0       12  [(149705, 8.133953094482422), (254632, 8.13036...\n",
       "1       13  [(345976, 7.779404163360596), (63170, 7.649724...\n",
       "2       14  [(345976, 8.195059776306152), (277538, 8.04972..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userRecs.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d9ff1-f705-48e1-adbe-1c89fc0f5372",
   "metadata": {},
   "source": [
    "- https://medium.com/@sinha.raunak/recommendation-systems-pyspark-als-model-evaluation-rmse-map-k-recall-k-ndcg-k-477bf6df893e\n",
    "\n",
    "- https://github.com/CGrannan/building-boardgame-recommendation-systems/blob/master/spark_als_recommendation.ipynb (but no ndcg@k)\n",
    "\n",
    "fix the code below tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ab6c1-7ebc-43d4-88aa-84bca47705b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get rated movie array\n",
    "\n",
    "from pyspark.sql.functions import collect_list, col, row_number, when\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.evaluation import RankingEvaluator\n",
    "\n",
    "# extract best performing model \n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# cross join users & movies to create a list \n",
    "# of all users and movie combinations\n",
    "all_users = dfs_train.select('user').distinct()\n",
    "all_movies = dfs_train.select('movie').distinct()\n",
    "users_x_movies = all_users.crossJoin(all_movies)\n",
    "\n",
    "# get predictions\n",
    "dfs_preds = best_model.transform(users_x_movies)\n",
    "\n",
    "# join preds and train dataset to get all preds & ratings\n",
    "# the unrated user x movie pairs will be NULL \n",
    "dfs_preds_and_ratings = dfs_preds.alias('preds').join(\n",
    "    dfs_train.alias('train'),\n",
    "    (dfs_preds['user']==dfs_train['user']) & \n",
    "    (dfs_preds['movie']==dfs_train['movie']),\n",
    "    how='outer')\n",
    "\n",
    "# filter out the \"seen\" movies from prediction\n",
    "# get preds for unrated user x movie pairs \n",
    "# using rating col which will contain NULLs\n",
    "dfs_preds_final = dfs_preds_and_ratings.filter(\n",
    "    col('train.rating').isNull()\n",
    ").select('preds.user', 'preds.movie', 'preds.prediction')\n",
    "\n",
    "# threshold for filtering predicted ratings & actual ratings\n",
    "thresh = 4.0 \n",
    "\n",
    "# filter predictions using threshold\n",
    "# rank order the predictions by predicted ratings\n",
    "dfs_preds_thresh_ranked = dfs_preds_final.filter(\n",
    "    col('prediction') >= thresh\n",
    "    ).orderBy('user', col('prediction').desc())\n",
    "dfs_preds_thresh_ranked_grouped = dfs_preds_thresh_ranked.groupBy('user').agg(\n",
    "    collect_list(col('movie').cast('double')).alias('predicted_movie_arr')\n",
    "    )\n",
    "\n",
    "# filter test dataset using threshold\n",
    "# rank order the test dataset by predicted ratings\n",
    "dfs_test_thresh_ranked = dfs_test.filter(\n",
    "    col('rating') >= thresh\n",
    "    ).orderBy('user', col('rating').desc())\n",
    "dfs_test_thresh_ranked_grouped = dfs_test_thresh_ranked.groupBy('user').agg(\n",
    "    collect_list(col('movie').cast('double')).alias('rated_movie_arr')\n",
    ")\n",
    "\n",
    "# inner join ranked test dataset with predictions \n",
    "# for every user to get two columns per user \n",
    "dfs_preds_thresh_for_eval = dfs_test_thresh_ranked_grouped.join(dfs_preds_thresh_ranked_grouped, on='user', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb29329-8319-4980-8fad-bef03fa4816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RankingEvaluator(\n",
    "    labelCol='rated_movie_arr', \n",
    "    predictionCol='predicted_movie_arr', \n",
    "    metricName='ndcgAtK', \n",
    "    k=10\n",
    ")\n",
    "ndcg_k = evaluator.evaluate(dfs_preds_thresh_for_eval)\n",
    "print(f\"NDCG at k={k} : {ndcg_k}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
