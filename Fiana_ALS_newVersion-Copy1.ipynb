{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f01185-3744-40aa-a125-7288504a5de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:22:37.582154Z",
     "iopub.status.busy": "2025-11-11T06:22:37.581372Z",
     "iopub.status.idle": "2025-11-11T06:22:39.620441Z",
     "shell.execute_reply": "2025-11-11T06:22:39.619106Z",
     "shell.execute_reply.started": "2025-11-11T06:22:37.582096Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17daf6c-be8a-4f96-a3f4-3cf2ca44c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./als_spark_checkpoints\"\n",
    "\n",
    "# Check if folder exists\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)   # Create folder\n",
    "    print(f\"Folder created: {folder_path}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560032f5-5b1a-4951-bced-bb25014be8a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:22:39.622227Z",
     "iopub.status.busy": "2025-11-11T06:22:39.621854Z",
     "iopub.status.idle": "2025-11-11T06:22:45.138813Z",
     "shell.execute_reply": "2025-11-11T06:22:45.136822Z",
     "shell.execute_reply.started": "2025-11-11T06:22:39.622205Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "     .builder\n",
    "     .master('local[*]') # tells you master is 1 laptop using all 4 executors\n",
    "     .config(\"spark.driver.memory\", \"8g\")\n",
    "     .config(\"spark.executor.memory\", \"8g\")\n",
    "     .config(\"spark.sql.shuffle.partitions\", \"8\")  # reduce for local\n",
    "     .getOrCreate()) # make new or get latest session\n",
    "\n",
    "spark.sparkContext.setCheckpointDir(\"./als_spark_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91af199-9145-4e22-bcc6-ea0fad56df3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:22:45.141913Z",
     "iopub.status.busy": "2025-11-11T06:22:45.141202Z",
     "iopub.status.idle": "2025-11-11T06:22:48.228331Z",
     "shell.execute_reply": "2025-11-11T06:22:48.226576Z",
     "shell.execute_reply.started": "2025-11-11T06:22:45.141848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read board game geek file on spark\n",
    "schema = \"\"\"\n",
    "_c0 INT,\n",
    "user STRING,\n",
    "rating FLOAT,\n",
    "comment STRING,\n",
    "id INT, \n",
    "name STRING\n",
    "\"\"\"\n",
    "# Fix quote handling for comments column \n",
    "df_spark = spark.read.csv(\n",
    "    \"/mnt/data/public/bgg/bgg-19m-reviews.csv\",\n",
    "    sep=',', header=True,\n",
    "    schema=schema,\n",
    "    multiLine=True,\n",
    "    quote='\"',\n",
    "    escape='\"')\n",
    "df_spark = df_spark.drop(\"_c0\", \"comment\", \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b8befb-56a1-4115-8087-191e58c653c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:22:48.245652Z",
     "iopub.status.busy": "2025-11-11T06:22:48.245067Z",
     "iopub.status.idle": "2025-11-11T06:23:24.735543Z",
     "shell.execute_reply": "2025-11-11T06:23:24.733572Z",
     "shell.execute_reply.started": "2025-11-11T06:22:48.245595Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map user name to integer\n",
    "user_indexer = StringIndexer(inputCol=\"user\", outputCol=\"user_id\")\n",
    "df_spark_indexed = user_indexer.fit(df_spark).transform(df_spark)\n",
    "\n",
    "# Save Spark DF mapping of user to User ID\n",
    "user_mapping = df_spark_indexed.select(\"user\", \"user_id\").distinct()\n",
    "df_spark_indexed = df_spark_indexed.drop(\"user\")\n",
    "\n",
    "# Change item column name for unformity\n",
    "df_spark_indexed = df_spark_indexed.withColumnRenamed(\"id\", \"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc361b6b-b718-42f8-96b2-9e7666dd1fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:23:24.738863Z",
     "iopub.status.busy": "2025-11-11T06:23:24.738044Z",
     "iopub.status.idle": "2025-11-11T06:23:26.702500Z",
     "shell.execute_reply": "2025-11-11T06:23:26.700964Z",
     "shell.execute_reply.started": "2025-11-11T06:23:24.738770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+\n",
      "|rating|item_id| user_id|\n",
      "+------+-------+--------+\n",
      "|  10.0|  30549|   201.0|\n",
      "|  10.0|  30549|  6591.0|\n",
      "|  10.0|  30549|   631.0|\n",
      "|  10.0|  30549|  1705.0|\n",
      "|  10.0|  30549|  5796.0|\n",
      "|  10.0|  30549|    78.0|\n",
      "|  10.0|  30549|393225.0|\n",
      "|  10.0|  30549|233206.0|\n",
      "|  10.0|  30549| 22517.0|\n",
      "|  10.0|  30549| 87298.0|\n",
      "+------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_indexed.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4fe7ae-e982-4e95-a7e5-cb6f1fce9503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:23:26.704760Z",
     "iopub.status.busy": "2025-11-11T06:23:26.704118Z",
     "iopub.status.idle": "2025-11-11T06:23:46.974188Z",
     "shell.execute_reply": "2025-11-11T06:23:46.973127Z",
     "shell.execute_reply.started": "2025-11-11T06:23:26.704702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+\n",
      "|rating|item_id|user_id|\n",
      "+------+-------+-------+\n",
      "|     0|      0|      0|\n",
      "+------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count nulls per column\n",
    "null_counts = df_spark_indexed.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_spark_indexed.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bfe0956-aca8-4659-a0b5-adcba5f2e00f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:23:46.975648Z",
     "iopub.status.busy": "2025-11-11T06:23:46.975292Z",
     "iopub.status.idle": "2025-11-11T06:23:46.983076Z",
     "shell.execute_reply": "2025-11-11T06:23:46.981936Z",
     "shell.execute_reply.started": "2025-11-11T06:23:46.975609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:/home2/bsdsba2027/rvelasco/BDCC Labs/BDCC_Lab1/als_spark_checkpoints/d1fca76c-3798-40c4-bb63-68e8c690625f\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext.getCheckpointDir())  # checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3650a1a7-d611-4738-8a41-3806e6c1fa43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:23:46.984962Z",
     "iopub.status.busy": "2025-11-11T06:23:46.984517Z",
     "iopub.status.idle": "2025-11-11T06:24:15.030404Z",
     "shell.execute_reply": "2025-11-11T06:24:15.028940Z",
     "shell.execute_reply.started": "2025-11-11T06:23:46.984922Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/socket.py\", line 720, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m train, test \u001b[38;5;241m=\u001b[39m df_spark_indexed\u001b[38;5;241m.\u001b[39mrandomSplit([\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.2\u001b[39m])\n\u001b[1;32m      3\u001b[0m als \u001b[38;5;241m=\u001b[39m ALS(rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, maxIter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[1;32m      4\u001b[0m           userCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, itemCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m           ratingCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m\"\u001b[39m, coldStartStrategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m           checkpointInterval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Saves to disk after n iterations\u001b[39;00m\n\u001b[1;32m      7\u001b[0m          )\n\u001b[0;32m----> 8\u001b[0m als_model \u001b[38;5;241m=\u001b[39m \u001b[43mals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py:203\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    208\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py:395\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 395\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py:392\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train an ALS model\n",
    "train, test = df_spark_indexed.randomSplit([0.8, 0.2])\n",
    "als = ALS(rank=2, maxIter=5, \n",
    "          userCol=\"user_id\", itemCol='item_id', \n",
    "          ratingCol=\"rating\", coldStartStrategy='drop',\n",
    "          checkpointInterval=10  # Saves to disk after n iterations\n",
    "         )\n",
    "als_model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5a06e0-a970-4c9d-adda-c17fabbbdf9f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-11T06:24:15.030844Z",
     "iopub.status.idle": "2025-11-11T06:24:15.031110Z",
     "shell.execute_reply": "2025-11-11T06:24:15.030982Z",
     "shell.execute_reply.started": "2025-11-11T06:24:15.030967Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = als_model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error:\" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb940c-1365-4705-92d6-a7ef930b3ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:24:27.550156Z",
     "iopub.status.busy": "2025-11-11T06:24:27.548701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 10 1.3354120006135488\n"
     ]
    }
   ],
   "source": [
    "train, test = df_spark_indexed.randomSplit([0.8, 0.2])\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "# Warning! This cell takes a while to run.\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "reg_params = [.01, .005, .001]\n",
    "for reg_param in reg_params:\n",
    "  tuning_als = ALS(regParam = reg_param,\n",
    "            userCol='user_id', itemCol='item_id', \n",
    "            ratingCol='rating', coldStartStrategy='drop')\n",
    "\n",
    "  param_grid = ParamGridBuilder()\\\n",
    "                .addGrid(als.rank, [2, 4, 8, 12, 16])\\\n",
    "                .build()\n",
    "\n",
    "  cv = CrossValidator(estimator=tuning_als, estimatorParamMaps=param_grid, \n",
    "                      evaluator=evaluator, parallelism=4)\n",
    "  tuned_model= cv.fit(train)\n",
    "  predictions = tuned_model.transform(test)\n",
    "  evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                  predictionCol=\"prediction\")\n",
    "  rmse = evaluator.evaluate(predictions)\n",
    "  print(reg_param, tuned_model.bestModel.rank, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ffd2d-2331-4086-a407-7530276d80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list, col, size, slice\n",
    "from pyspark.ml.evaluation import RankingEvaluator\n",
    "\n",
    "print(\"Building evaluation dataset...\")\n",
    "\n",
    "# Get top-10 recommendations\n",
    "k = 10\n",
    "userRecs = als_model.recommendForAllUsers(k)\n",
    "\n",
    "dfs_preds_grouped = userRecs.select(\n",
    "    col('user_id'),\n",
    "    col('recommendations.item_id').alias('predicted_item_id_arr')\n",
    ").withColumn(\n",
    "    'predicted_item_id_arr',\n",
    "    col('predicted_item_id_arr').cast('array<double>')\n",
    ")\n",
    "\n",
    "# Get actual highly-rated items from test\n",
    "thresh = 4.0\n",
    "test_thresh_grouped = test.filter(\n",
    "    col('rating') >= thresh\n",
    ").groupBy('user_id').agg(\n",
    "    collect_list(col('item_id').cast('double')).alias('rated_item_id_arr')\n",
    ")\n",
    "\n",
    "# Join predictions with actuals\n",
    "dfs_preds_thresh_for_eval = test_thresh_grouped.join(\n",
    "    dfs_preds_grouped,\n",
    "    on='user_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# CRITICAL: Limit array sizes to reduce computation\n",
    "dfs_preds_limited = dfs_preds_thresh_for_eval.withColumn(\n",
    "    'rated_item_id_arr',\n",
    "    slice('rated_item_id_arr', 1, 20)  # Max 20 items\n",
    ").withColumn(\n",
    "    'predicted_item_id_arr',\n",
    "    slice('predicted_item_id_arr', 1, 10)  # Max 10 predictions\n",
    ")\n",
    "\n",
    "print(\"âœ“ Evaluation dataset ready\")\n",
    "\n",
    "# Sample VERY small first - only 0.5%\n",
    "print(\"Sampling 0.5% of users...\")\n",
    "dfs_preds_sampled = dfs_preds_limited.sample(fraction=0.005, seed=42)\n",
    "dfs_preds_sampled.cache()\n",
    "\n",
    "sample_count = dfs_preds_sampled.count()\n",
    "print(f\"Sample size: {sample_count:,} users\")\n",
    "\n",
    "if sample_count > 0:\n",
    "    # Evaluate\n",
    "    evaluator = RankingEvaluator(\n",
    "        labelCol='rated_item_id_arr',\n",
    "        predictionCol='predicted_item_id_arr',\n",
    "        metricName='ndcgAtK',\n",
    "        k=3\n",
    "    )\n",
    "    \n",
    "    print(\"Evaluating NDCG...\")\n",
    "    ndcg_k = evaluator.evaluate(dfs_preds_sampled)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"NDCG at k=3: {ndcg_k:.6f}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Quick diagnostics\n",
    "    print(\"\\nArray size check:\")\n",
    "    dfs_preds_sampled.select(\n",
    "        size('rated_item_id_arr').alias('actual_size'),\n",
    "        size('predicted_item_id_arr').alias('pred_size')\n",
    "    ).describe().show()\n",
    "else:\n",
    "    print(\"ERROR: Sample is empty!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00709ded-1a7b-4852-b38d-0715f94243c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:14:25.630205Z",
     "iopub.status.busy": "2025-11-10T17:14:25.629455Z",
     "iopub.status.idle": "2025-11-10T17:14:25.937138Z",
     "shell.execute_reply": "2025-11-10T17:14:25.936134Z",
     "shell.execute_reply.started": "2025-11-10T17:14:25.630145Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m movieRecs \u001b[38;5;241m=\u001b[39m als_model\u001b[38;5;241m.\u001b[39mrecommendForAllItems(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Generate top 10 movie recommendations for a specified set of users\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m users \u001b[38;5;241m=\u001b[39m \u001b[43mratings\u001b[49m\u001b[38;5;241m.\u001b[39mselect(als\u001b[38;5;241m.\u001b[39mgetUserCol())\u001b[38;5;241m.\u001b[39mdistinct()\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      8\u001b[0m userSubsetRecs \u001b[38;5;241m=\u001b[39m als_model\u001b[38;5;241m.\u001b[39mrecommendForUserSubset(users, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Generate top 10 user recommendations for a specified set of movies\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ratings' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = als_model.recommendForAllUsers(10)\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = als_model.recommendForAllItems(10)\n",
    "\n",
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = als_model.recommendForUserSubset(users, 10)\n",
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "movieSubSetRecs = als_model.recommendForItemSubset(movies, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1486d0ac-1e4f-4482-ad24-a2dee26c5066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:15:31.451138Z",
     "iopub.status.busy": "2025-11-10T17:15:31.450410Z",
     "iopub.status.idle": "2025-11-10T17:18:06.680040Z",
     "shell.execute_reply": "2025-11-10T17:18:06.679187Z",
     "shell.execute_reply.started": "2025-11-10T17:15:31.451077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>[(149705, 8.133953094482422), (254632, 8.13036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>[(345976, 7.779404163360596), (63170, 7.649724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>[(345976, 8.195059776306152), (277538, 8.04972...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                    recommendations\n",
       "0       12  [(149705, 8.133953094482422), (254632, 8.13036...\n",
       "1       13  [(345976, 7.779404163360596), (63170, 7.649724...\n",
       "2       14  [(345976, 8.195059776306152), (277538, 8.04972..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userRecs.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7608180a-3fa6-4763-8f22-48fc34ecfe24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T05:51:25.851898Z",
     "iopub.status.busy": "2025-11-11T05:51:25.850705Z",
     "iopub.status.idle": "2025-11-11T05:51:25.919423Z",
     "shell.execute_reply": "2025-11-11T05:51:25.918184Z",
     "shell.execute_reply.started": "2025-11-11T05:51:25.851833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Diagnostic Checks\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_thresh_grouped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 1. How many users have actual ratings in test?\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUsers with rated items: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtest_thresh_grouped\u001b[49m\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 2. How many users got recommendations?\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsers with predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdfs_preds_grouped\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_thresh_grouped' is not defined"
     ]
    }
   ],
   "source": [
    "# Check the data quality\n",
    "print(\"=\"*50)\n",
    "print(\"Diagnostic Checks\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. How many users have actual ratings in test?\n",
    "print(f\"\\nUsers with rated items: {test_thresh_grouped.count():,}\")\n",
    "\n",
    "# 2. How many users got recommendations?\n",
    "print(f\"Users with predictions: {dfs_preds_grouped.count():,}\")\n",
    "\n",
    "# 3. How many users have BOTH?\n",
    "print(f\"Users in evaluation: {dfs_preds_thresh_for_eval.count():,}\")\n",
    "\n",
    "# 4. Look at array sizes\n",
    "print(\"\\nArray size statistics:\")\n",
    "dfs_preds_thresh_for_eval.select(\n",
    "    F.size('rated_item_id_arr').alias('actual_size'),\n",
    "    F.size('predicted_item_id_arr').alias('pred_size')\n",
    ").describe().show()\n",
    "\n",
    "# 5. Check for overlap - are ANY predictions correct?\n",
    "print(\"\\nSample of predictions vs actuals:\")\n",
    "dfs_preds_thresh_for_eval.select(\n",
    "    'user_id',\n",
    "    'rated_item_id_arr',\n",
    "    'predicted_item_id_arr'\n",
    ").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10676095-8f54-4a68-8b9b-17eb38d13667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T05:30:46.302907Z",
     "iopub.status.busy": "2025-11-11T05:30:46.301926Z",
     "iopub.status.idle": "2025-11-11T05:30:46.704638Z",
     "shell.execute_reply": "2025-11-11T05:30:46.703490Z",
     "shell.execute_reply.started": "2025-11-11T05:30:46.302868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1% of users for evaluation...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dfs_preds_thresh_for_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampling 1\u001b[39m\u001b[38;5;132;01m% o\u001b[39;00m\u001b[38;5;124mf users for evaluation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Sample WITHOUT counting first\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m dfs_preds_sampled \u001b[38;5;241m=\u001b[39m \u001b[43mdfs_preds_thresh_for_eval\u001b[49m\u001b[38;5;241m.\u001b[39msample(fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Cache the sample\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dfs_preds_sampled\u001b[38;5;241m.\u001b[39mcache()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfs_preds_thresh_for_eval' is not defined"
     ]
    }
   ],
   "source": [
    "# DON'T count! Just sample immediately\n",
    "print(\"Sampling 1% of users for evaluation...\")\n",
    "\n",
    "# Sample WITHOUT counting first\n",
    "dfs_preds_sampled = dfs_preds_thresh_for_eval.sample(fraction=0.01, seed=42)\n",
    "\n",
    "# Cache the sample\n",
    "dfs_preds_sampled.cache()\n",
    "\n",
    "# Now count only the SAMPLE (much smaller)\n",
    "sample_count = dfs_preds_sampled.count()\n",
    "print(f\"Sampled users: {sample_count:,}\")\n",
    "\n",
    "# Evaluate on the sample\n",
    "evaluator = RankingEvaluator(\n",
    "    labelCol='rated_item_id_arr',\n",
    "    predictionCol='predicted_item_id_arr',\n",
    "    metricName='ndcgAtK',\n",
    "    k=3\n",
    ")\n",
    "\n",
    "ndcg_k = evaluator.evaluate(dfs_preds_sampled)\n",
    "print(f\"NDCG at k=3 (on {sample_count:,} users): {ndcg_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76536cfa-10bd-4a03-b800-65ca86f05baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T04:27:34.571068Z",
     "iopub.status.busy": "2025-11-11T04:27:34.569663Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list, col, explode\n",
    "from pyspark.ml.evaluation import RankingEvaluator\n",
    "\n",
    "# Step 1: Get predictions using the efficient built-in method\n",
    "# This returns top N recommendations per user (much smaller dataset!)\n",
    "k = 10  # or however many recommendations you want\n",
    "userRecs = als_model.recommendForAllUsers(k)\n",
    "\n",
    "# Step 2: Extract item IDs from recommendations\n",
    "# userRecs has format: user_id | recommendations (array of struct(item_id, rating))\n",
    "dfs_preds_grouped = userRecs.select(\n",
    "    col('user_id'),\n",
    "    col('recommendations.item_id').alias('predicted_item_id_arr')\n",
    ").withColumn(\n",
    "    'predicted_item_id_arr',\n",
    "    col('predicted_item_id_arr').cast('array<double>')\n",
    ")\n",
    "\n",
    "# Step 3: Get actual highly-rated items from test set\n",
    "thresh = 4.0\n",
    "test_thresh_grouped = test.filter(\n",
    "    col('rating') >= thresh\n",
    ").groupBy('user_id').agg(\n",
    "    collect_list(col('item_id').cast('double')).alias('rated_item_id_arr')\n",
    ")\n",
    "\n",
    "# Step 4: Join predictions with actuals\n",
    "dfs_preds_thresh_for_eval = test_thresh_grouped.join(\n",
    "    dfs_preds_grouped, \n",
    "    on='user_id', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Step 5: Check size (should be manageable now!)\n",
    "row_count = dfs_preds_thresh_for_eval.count()\n",
    "print(f\"Number of rows: {row_count:,}\")\n",
    "\n",
    "# Step 6: Evaluate\n",
    "evaluator = RankingEvaluator(\n",
    "    labelCol='rated_item_id_arr',\n",
    "    predictionCol='predicted_item_id_arr',\n",
    "    metricName='ndcgAtK',\n",
    "    k=3\n",
    ")\n",
    "ndcg_k = evaluator.evaluate(dfs_preds_thresh_for_eval)\n",
    "print(f\"NDCG at k=3: {ndcg_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d9ff1-f705-48e1-adbe-1c89fc0f5372",
   "metadata": {},
   "source": [
    "- https://medium.com/@sinha.raunak/recommendation-systems-pyspark-als-model-evaluation-rmse-map-k-recall-k-ndcg-k-477bf6df893e\n",
    "\n",
    "- https://github.com/CGrannan/building-boardgame-recommendation-systems/blob/master/spark_als_recommendation.ipynb (but no ndcg@k)\n",
    "\n",
    "fix the code below tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e5e84-64c9-4f9c-b585-48edae4d9e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
