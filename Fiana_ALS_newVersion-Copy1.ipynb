{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f01185-3744-40aa-a125-7288504a5de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T06:14:28.245487Z",
     "iopub.status.busy": "2025-11-12T06:14:28.244532Z",
     "iopub.status.idle": "2025-11-12T06:14:44.243198Z",
     "shell.execute_reply": "2025-11-12T06:14:44.242111Z",
     "shell.execute_reply.started": "2025-11-12T06:14:28.245372Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17daf6c-be8a-4f96-a3f4-3cf2ca44c79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T06:14:44.244732Z",
     "iopub.status.busy": "2025-11-12T06:14:44.244400Z",
     "iopub.status.idle": "2025-11-12T06:14:44.257268Z",
     "shell.execute_reply": "2025-11-12T06:14:44.254942Z",
     "shell.execute_reply.started": "2025-11-12T06:14:44.244711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists: ./als_spark_checkpoints\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./als_spark_checkpoints\"\n",
    "\n",
    "# Check if folder exists\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)   # Create folder\n",
    "    print(f\"Folder created: {folder_path}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560032f5-5b1a-4951-bced-bb25014be8a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T06:14:44.260135Z",
     "iopub.status.busy": "2025-11-12T06:14:44.258681Z",
     "iopub.status.idle": "2025-11-12T06:14:52.999819Z",
     "shell.execute_reply": "2025-11-12T06:14:52.997818Z",
     "shell.execute_reply.started": "2025-11-12T06:14:44.260112Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "     .builder\n",
    "     .master('local[*]') # tells you master is 1 laptop using all 4 executors\n",
    "     .config(\"spark.driver.memory\", \"8g\")\n",
    "     .config(\"spark.executor.memory\", \"8g\")\n",
    "     .config(\"spark.sql.shuffle.partitions\", \"8\")  # reduce for local\n",
    "     .getOrCreate()) # make new or get latest session\n",
    "\n",
    "spark.sparkContext.setCheckpointDir(\"./als_spark_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91af199-9145-4e22-bcc6-ea0fad56df3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T06:14:53.004811Z",
     "iopub.status.busy": "2025-11-12T06:14:53.004096Z",
     "iopub.status.idle": "2025-11-12T06:15:00.260066Z",
     "shell.execute_reply": "2025-11-12T06:15:00.258137Z",
     "shell.execute_reply.started": "2025-11-12T06:14:53.004722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read board game geek file on spark\n",
    "schema = \"\"\"\n",
    "_c0 INT,\n",
    "user STRING,\n",
    "rating FLOAT,\n",
    "comment STRING,\n",
    "id INT, \n",
    "name STRING\n",
    "\"\"\"\n",
    "# Fix quote handling for comments column \n",
    "df_spark = spark.read.csv(\n",
    "    \"/mnt/data/public/bgg/bgg-19m-reviews.csv\",\n",
    "    sep=',', header=True,\n",
    "    schema=schema,\n",
    "    multiLine=True,\n",
    "    quote='\"',\n",
    "    escape='\"')\n",
    "df_spark = df_spark.drop(\"_c0\", \"comment\", \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b8befb-56a1-4115-8087-191e58c653c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T06:15:23.812017Z",
     "iopub.status.busy": "2025-11-12T06:15:23.810658Z",
     "iopub.status.idle": "2025-11-12T06:16:03.066246Z",
     "shell.execute_reply": "2025-11-12T06:16:03.065281Z",
     "shell.execute_reply.started": "2025-11-12T06:15:23.811955Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map user name to integer\n",
    "user_indexer = StringIndexer(inputCol=\"user\", outputCol=\"user_id\")\n",
    "df_spark_indexed = user_indexer.fit(df_spark).transform(df_spark)\n",
    "\n",
    "# Save Spark DF mapping of user to User ID\n",
    "user_mapping = df_spark_indexed.select(\"user\", \"user_id\").distinct()\n",
    "df_spark_indexed = df_spark_indexed.drop(\"user\")\n",
    "\n",
    "# Change item column name for unformity\n",
    "df_spark_indexed = df_spark_indexed.withColumnRenamed(\"id\", \"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc361b6b-b718-42f8-96b2-9e7666dd1fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T06:16:06.738551Z",
     "iopub.status.busy": "2025-11-12T06:16:06.737301Z",
     "iopub.status.idle": "2025-11-12T06:16:09.704488Z",
     "shell.execute_reply": "2025-11-12T06:16:09.703232Z",
     "shell.execute_reply.started": "2025-11-12T06:16:06.738490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+\n",
      "|rating|item_id| user_id|\n",
      "+------+-------+--------+\n",
      "|  10.0|  30549|   201.0|\n",
      "|  10.0|  30549|  6591.0|\n",
      "|  10.0|  30549|   631.0|\n",
      "|  10.0|  30549|  1705.0|\n",
      "|  10.0|  30549|  5796.0|\n",
      "|  10.0|  30549|    78.0|\n",
      "|  10.0|  30549|393225.0|\n",
      "|  10.0|  30549|233206.0|\n",
      "|  10.0|  30549| 22517.0|\n",
      "|  10.0|  30549| 87298.0|\n",
      "+------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_indexed.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5973f24-825b-4ca4-9652-371d96c69106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T06:17:00.587996Z",
     "iopub.status.busy": "2025-11-12T06:17:00.587422Z",
     "iopub.status.idle": "2025-11-12T06:17:23.620290Z",
     "shell.execute_reply": "2025-11-12T06:17:23.618604Z",
     "shell.execute_reply.started": "2025-11-12T06:17:00.587952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|item_id| count|\n",
      "+-------+------+\n",
      "|     13|108195|\n",
      "| 230802| 63019|\n",
      "|  70323| 61203|\n",
      "|  65244| 44555|\n",
      "|  98778| 41619|\n",
      "| 147020| 38601|\n",
      "|    463| 34424|\n",
      "|  37111| 33979|\n",
      "| 205637| 33129|\n",
      "|  31481| 30985|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_sample = (\n",
    "    df_spark_indexed.groupby(\"item_id\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "df_spark_sample.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb940c-1365-4705-92d6-a7ef930b3ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:24:27.550156Z",
     "iopub.status.busy": "2025-11-11T06:24:27.548701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 10 1.3354120006135488\n"
     ]
    }
   ],
   "source": [
    "train, test = df_spark_indexed.randomSplit([0.8, 0.2])\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "# Warning! This cell takes a while to run.\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "reg_params = [.01, .005, .001]\n",
    "for reg_param in reg_params:\n",
    "  tuning_als = ALS(regParam = reg_param,\n",
    "            userCol='user_id', itemCol='item_id', \n",
    "            ratingCol='rating', coldStartStrategy='drop')\n",
    "\n",
    "  param_grid = ParamGridBuilder()\\\n",
    "                .addGrid(als.rank, [2, 4, 8, 12, 16])\\\n",
    "                .build()\n",
    "\n",
    "  cv = CrossValidator(estimator=tuning_als, estimatorParamMaps=param_grid, \n",
    "                      evaluator=evaluator, parallelism=4)\n",
    "  tuned_model= cv.fit(train)\n",
    "  predictions = tuned_model.transform(test)\n",
    "  evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                  predictionCol=\"prediction\")\n",
    "  rmse = evaluator.evaluate(predictions)\n",
    "  print(reg_param, tuned_model.bestModel.rank, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ffd2d-2331-4086-a407-7530276d80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list, col, size, slice\n",
    "from pyspark.ml.evaluation import RankingEvaluator\n",
    "\n",
    "print(\"Building evaluation dataset...\")\n",
    "\n",
    "# Get top-10 recommendations\n",
    "k = 10\n",
    "userRecs = als_model.recommendForAllUsers(k)\n",
    "\n",
    "dfs_preds_grouped = userRecs.select(\n",
    "    col('user_id'),\n",
    "    col('recommendations.item_id').alias('predicted_item_id_arr')\n",
    ").withColumn(\n",
    "    'predicted_item_id_arr',\n",
    "    col('predicted_item_id_arr').cast('array<double>')\n",
    ")\n",
    "\n",
    "# Get actual highly-rated items from test\n",
    "thresh = 4.0\n",
    "test_thresh_grouped = test.filter(\n",
    "    col('rating') >= thresh\n",
    ").groupBy('user_id').agg(\n",
    "    collect_list(col('item_id').cast('double')).alias('rated_item_id_arr')\n",
    ")\n",
    "\n",
    "# Join predictions with actuals\n",
    "dfs_preds_thresh_for_eval = test_thresh_grouped.join(\n",
    "    dfs_preds_grouped,\n",
    "    on='user_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# CRITICAL: Limit array sizes to reduce computation\n",
    "dfs_preds_limited = dfs_preds_thresh_for_eval.withColumn(\n",
    "    'rated_item_id_arr',\n",
    "    slice('rated_item_id_arr', 1, 20)  # Max 20 items\n",
    ").withColumn(\n",
    "    'predicted_item_id_arr',\n",
    "    slice('predicted_item_id_arr', 1, 10)  # Max 10 predictions\n",
    ")\n",
    "\n",
    "print(\"âœ“ Evaluation dataset ready\")\n",
    "\n",
    "# Sample VERY small first - only 0.5%\n",
    "print(\"Sampling 0.5% of users...\")\n",
    "dfs_preds_sampled = dfs_preds_limited.sample(fraction=0.005, seed=42)\n",
    "dfs_preds_sampled.cache()\n",
    "\n",
    "sample_count = dfs_preds_sampled.count()\n",
    "print(f\"Sample size: {sample_count:,} users\")\n",
    "\n",
    "if sample_count > 0:\n",
    "    # Evaluate\n",
    "    evaluator = RankingEvaluator(\n",
    "        labelCol='rated_item_id_arr',\n",
    "        predictionCol='predicted_item_id_arr',\n",
    "        metricName='ndcgAtK',\n",
    "        k=3\n",
    "    )\n",
    "    \n",
    "    print(\"Evaluating NDCG...\")\n",
    "    ndcg_k = evaluator.evaluate(dfs_preds_sampled)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"NDCG at k=3: {ndcg_k:.6f}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Quick diagnostics\n",
    "    print(\"\\nArray size check:\")\n",
    "    dfs_preds_sampled.select(\n",
    "        size('rated_item_id_arr').alias('actual_size'),\n",
    "        size('predicted_item_id_arr').alias('pred_size')\n",
    "    ).describe().show()\n",
    "else:\n",
    "    print(\"ERROR: Sample is empty!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00709ded-1a7b-4852-b38d-0715f94243c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:14:25.630205Z",
     "iopub.status.busy": "2025-11-10T17:14:25.629455Z",
     "iopub.status.idle": "2025-11-10T17:14:25.937138Z",
     "shell.execute_reply": "2025-11-10T17:14:25.936134Z",
     "shell.execute_reply.started": "2025-11-10T17:14:25.630145Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m movieRecs \u001b[38;5;241m=\u001b[39m als_model\u001b[38;5;241m.\u001b[39mrecommendForAllItems(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Generate top 10 movie recommendations for a specified set of users\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m users \u001b[38;5;241m=\u001b[39m \u001b[43mratings\u001b[49m\u001b[38;5;241m.\u001b[39mselect(als\u001b[38;5;241m.\u001b[39mgetUserCol())\u001b[38;5;241m.\u001b[39mdistinct()\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      8\u001b[0m userSubsetRecs \u001b[38;5;241m=\u001b[39m als_model\u001b[38;5;241m.\u001b[39mrecommendForUserSubset(users, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Generate top 10 user recommendations for a specified set of movies\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ratings' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = als_model.recommendForAllUsers(10)\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = als_model.recommendForAllItems(10)\n",
    "\n",
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = als_model.recommendForUserSubset(users, 10)\n",
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "movieSubSetRecs = als_model.recommendForItemSubset(movies, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1486d0ac-1e4f-4482-ad24-a2dee26c5066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:15:31.451138Z",
     "iopub.status.busy": "2025-11-10T17:15:31.450410Z",
     "iopub.status.idle": "2025-11-10T17:18:06.680040Z",
     "shell.execute_reply": "2025-11-10T17:18:06.679187Z",
     "shell.execute_reply.started": "2025-11-10T17:15:31.451077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>[(149705, 8.133953094482422), (254632, 8.13036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>[(345976, 7.779404163360596), (63170, 7.649724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>[(345976, 8.195059776306152), (277538, 8.04972...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                    recommendations\n",
       "0       12  [(149705, 8.133953094482422), (254632, 8.13036...\n",
       "1       13  [(345976, 7.779404163360596), (63170, 7.649724...\n",
       "2       14  [(345976, 8.195059776306152), (277538, 8.04972..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userRecs.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7608180a-3fa6-4763-8f22-48fc34ecfe24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T05:51:25.851898Z",
     "iopub.status.busy": "2025-11-11T05:51:25.850705Z",
     "iopub.status.idle": "2025-11-11T05:51:25.919423Z",
     "shell.execute_reply": "2025-11-11T05:51:25.918184Z",
     "shell.execute_reply.started": "2025-11-11T05:51:25.851833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Diagnostic Checks\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_thresh_grouped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 1. How many users have actual ratings in test?\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUsers with rated items: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtest_thresh_grouped\u001b[49m\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 2. How many users got recommendations?\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsers with predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdfs_preds_grouped\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_thresh_grouped' is not defined"
     ]
    }
   ],
   "source": [
    "# Check the data quality\n",
    "print(\"=\"*50)\n",
    "print(\"Diagnostic Checks\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. How many users have actual ratings in test?\n",
    "print(f\"\\nUsers with rated items: {test_thresh_grouped.count():,}\")\n",
    "\n",
    "# 2. How many users got recommendations?\n",
    "print(f\"Users with predictions: {dfs_preds_grouped.count():,}\")\n",
    "\n",
    "# 3. How many users have BOTH?\n",
    "print(f\"Users in evaluation: {dfs_preds_thresh_for_eval.count():,}\")\n",
    "\n",
    "# 4. Look at array sizes\n",
    "print(\"\\nArray size statistics:\")\n",
    "dfs_preds_thresh_for_eval.select(\n",
    "    F.size('rated_item_id_arr').alias('actual_size'),\n",
    "    F.size('predicted_item_id_arr').alias('pred_size')\n",
    ").describe().show()\n",
    "\n",
    "# 5. Check for overlap - are ANY predictions correct?\n",
    "print(\"\\nSample of predictions vs actuals:\")\n",
    "dfs_preds_thresh_for_eval.select(\n",
    "    'user_id',\n",
    "    'rated_item_id_arr',\n",
    "    'predicted_item_id_arr'\n",
    ").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10676095-8f54-4a68-8b9b-17eb38d13667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T05:30:46.302907Z",
     "iopub.status.busy": "2025-11-11T05:30:46.301926Z",
     "iopub.status.idle": "2025-11-11T05:30:46.704638Z",
     "shell.execute_reply": "2025-11-11T05:30:46.703490Z",
     "shell.execute_reply.started": "2025-11-11T05:30:46.302868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1% of users for evaluation...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dfs_preds_thresh_for_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampling 1\u001b[39m\u001b[38;5;132;01m% o\u001b[39;00m\u001b[38;5;124mf users for evaluation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Sample WITHOUT counting first\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m dfs_preds_sampled \u001b[38;5;241m=\u001b[39m \u001b[43mdfs_preds_thresh_for_eval\u001b[49m\u001b[38;5;241m.\u001b[39msample(fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Cache the sample\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dfs_preds_sampled\u001b[38;5;241m.\u001b[39mcache()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfs_preds_thresh_for_eval' is not defined"
     ]
    }
   ],
   "source": [
    "# DON'T count! Just sample immediately\n",
    "print(\"Sampling 1% of users for evaluation...\")\n",
    "\n",
    "# Sample WITHOUT counting first\n",
    "dfs_preds_sampled = dfs_preds_thresh_for_eval.sample(fraction=0.01, seed=42)\n",
    "\n",
    "# Cache the sample\n",
    "dfs_preds_sampled.cache()\n",
    "\n",
    "# Now count only the SAMPLE (much smaller)\n",
    "sample_count = dfs_preds_sampled.count()\n",
    "print(f\"Sampled users: {sample_count:,}\")\n",
    "\n",
    "# Evaluate on the sample\n",
    "evaluator = RankingEvaluator(\n",
    "    labelCol='rated_item_id_arr',\n",
    "    predictionCol='predicted_item_id_arr',\n",
    "    metricName='ndcgAtK',\n",
    "    k=3\n",
    ")\n",
    "\n",
    "ndcg_k = evaluator.evaluate(dfs_preds_sampled)\n",
    "print(f\"NDCG at k=3 (on {sample_count:,} users): {ndcg_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76536cfa-10bd-4a03-b800-65ca86f05baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T04:27:34.571068Z",
     "iopub.status.busy": "2025-11-11T04:27:34.569663Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list, col, explode\n",
    "from pyspark.ml.evaluation import RankingEvaluator\n",
    "\n",
    "# Step 1: Get predictions using the efficient built-in method\n",
    "# This returns top N recommendations per user (much smaller dataset!)\n",
    "k = 10  # or however many recommendations you want\n",
    "userRecs = als_model.recommendForAllUsers(k)\n",
    "\n",
    "# Step 2: Extract item IDs from recommendations\n",
    "# userRecs has format: user_id | recommendations (array of struct(item_id, rating))\n",
    "dfs_preds_grouped = userRecs.select(\n",
    "    col('user_id'),\n",
    "    col('recommendations.item_id').alias('predicted_item_id_arr')\n",
    ").withColumn(\n",
    "    'predicted_item_id_arr',\n",
    "    col('predicted_item_id_arr').cast('array<double>')\n",
    ")\n",
    "\n",
    "# Step 3: Get actual highly-rated items from test set\n",
    "thresh = 4.0\n",
    "test_thresh_grouped = test.filter(\n",
    "    col('rating') >= thresh\n",
    ").groupBy('user_id').agg(\n",
    "    collect_list(col('item_id').cast('double')).alias('rated_item_id_arr')\n",
    ")\n",
    "\n",
    "# Step 4: Join predictions with actuals\n",
    "dfs_preds_thresh_for_eval = test_thresh_grouped.join(\n",
    "    dfs_preds_grouped, \n",
    "    on='user_id', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Step 5: Check size (should be manageable now!)\n",
    "row_count = dfs_preds_thresh_for_eval.count()\n",
    "print(f\"Number of rows: {row_count:,}\")\n",
    "\n",
    "# Step 6: Evaluate\n",
    "evaluator = RankingEvaluator(\n",
    "    labelCol='rated_item_id_arr',\n",
    "    predictionCol='predicted_item_id_arr',\n",
    "    metricName='ndcgAtK',\n",
    "    k=3\n",
    ")\n",
    "ndcg_k = evaluator.evaluate(dfs_preds_thresh_for_eval)\n",
    "print(f\"NDCG at k=3: {ndcg_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d9ff1-f705-48e1-adbe-1c89fc0f5372",
   "metadata": {},
   "source": [
    "- https://medium.com/@sinha.raunak/recommendation-systems-pyspark-als-model-evaluation-rmse-map-k-recall-k-ndcg-k-477bf6df893e\n",
    "\n",
    "- https://github.com/CGrannan/building-boardgame-recommendation-systems/blob/master/spark_als_recommendation.ipynb (but no ndcg@k)\n",
    "\n",
    "fix the code below tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e5e84-64c9-4f9c-b585-48edae4d9e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
