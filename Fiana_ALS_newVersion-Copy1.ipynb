{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f01185-3744-40aa-a125-7288504a5de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:02:31.327393Z",
     "iopub.status.busy": "2025-11-11T06:02:31.326687Z",
     "iopub.status.idle": "2025-11-11T06:02:32.117485Z",
     "shell.execute_reply": "2025-11-11T06:02:32.116076Z",
     "shell.execute_reply.started": "2025-11-11T06:02:31.327331Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17daf6c-be8a-4f96-a3f4-3cf2ca44c79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:02:32.119107Z",
     "iopub.status.busy": "2025-11-11T06:02:32.118766Z",
     "iopub.status.idle": "2025-11-11T06:02:32.126538Z",
     "shell.execute_reply": "2025-11-11T06:02:32.124878Z",
     "shell.execute_reply.started": "2025-11-11T06:02:32.119069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists: ./als_spark_checkpoints\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./als_spark_checkpoints\"\n",
    "\n",
    "# Check if folder exists\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)   # Create folder\n",
    "    print(f\"Folder created: {folder_path}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560032f5-5b1a-4951-bced-bb25014be8a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:02:32.129309Z",
     "iopub.status.busy": "2025-11-11T06:02:32.128696Z",
     "iopub.status.idle": "2025-11-11T06:02:38.120868Z",
     "shell.execute_reply": "2025-11-11T06:02:38.118534Z",
     "shell.execute_reply.started": "2025-11-11T06:02:32.129256Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "     .builder\n",
    "     .master('local[*]') # tells you master is 1 laptop using all 4 executors\n",
    "     .config(\"spark.driver.memory\", \"8g\")\n",
    "     .config(\"spark.executor.memory\", \"8g\")\n",
    "     .config(\"spark.sql.shuffle.partitions\", \"8\")  # reduce for local\n",
    "     .getOrCreate()) # make new or get latest session\n",
    "\n",
    "spark.sparkContext.setCheckpointDir(\"./als_spark_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91af199-9145-4e22-bcc6-ea0fad56df3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:02:38.126186Z",
     "iopub.status.busy": "2025-11-11T06:02:38.125464Z",
     "iopub.status.idle": "2025-11-11T06:02:41.211896Z",
     "shell.execute_reply": "2025-11-11T06:02:41.209973Z",
     "shell.execute_reply.started": "2025-11-11T06:02:38.126114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read board game geek file on spark\n",
    "schema = \"\"\"\n",
    "_c0 INT,\n",
    "user STRING,\n",
    "rating FLOAT,\n",
    "comment STRING,\n",
    "id INT, \n",
    "name STRING\n",
    "\"\"\"\n",
    "# Fix quote handling for comments column \n",
    "df_spark = spark.read.csv(\n",
    "    \"/mnt/data/public/bgg/bgg-19m-reviews.csv\",\n",
    "    sep=',', header=True,\n",
    "    schema=schema,\n",
    "    multiLine=True,\n",
    "    quote='\"',\n",
    "    escape='\"')\n",
    "df_spark = df_spark.drop(\"_c0\", \"comment\", \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b8befb-56a1-4115-8087-191e58c653c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:02:41.214282Z",
     "iopub.status.busy": "2025-11-11T06:02:41.213645Z",
     "iopub.status.idle": "2025-11-11T06:03:15.301177Z",
     "shell.execute_reply": "2025-11-11T06:03:15.299831Z",
     "shell.execute_reply.started": "2025-11-11T06:02:41.214226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map user name to integer\n",
    "user_indexer = StringIndexer(inputCol=\"user\", outputCol=\"user_id\")\n",
    "df_spark_indexed = user_indexer.fit(df_spark).transform(df_spark)\n",
    "\n",
    "# Save Spark DF mapping of user to User ID\n",
    "user_mapping = df_spark_indexed.select(\"user\", \"user_id\").distinct()\n",
    "df_spark_indexed = df_spark_indexed.drop(\"user\")\n",
    "\n",
    "# Change item column name for unformity\n",
    "df_spark_indexed = df_spark_indexed.withColumnRenamed(\"id\", \"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968be38c-f754-4871-b2b9-2e8e8e483473",
   "metadata": {},
   "outputs": [],
   "source": [
    "868.3887082741884"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc361b6b-b718-42f8-96b2-9e7666dd1fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:03:15.302856Z",
     "iopub.status.busy": "2025-11-11T06:03:15.302546Z",
     "iopub.status.idle": "2025-11-11T06:03:16.939156Z",
     "shell.execute_reply": "2025-11-11T06:03:16.938284Z",
     "shell.execute_reply.started": "2025-11-11T06:03:15.302826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+\n",
      "|rating|item_id| user_id|\n",
      "+------+-------+--------+\n",
      "|  10.0|  30549|   201.0|\n",
      "|  10.0|  30549|  6591.0|\n",
      "|  10.0|  30549|   631.0|\n",
      "|  10.0|  30549|  1705.0|\n",
      "|  10.0|  30549|  5796.0|\n",
      "|  10.0|  30549|    78.0|\n",
      "|  10.0|  30549|393225.0|\n",
      "|  10.0|  30549|233206.0|\n",
      "|  10.0|  30549| 22517.0|\n",
      "|  10.0|  30549| 87298.0|\n",
      "+------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_indexed.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4fe7ae-e982-4e95-a7e5-cb6f1fce9503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:03:16.941143Z",
     "iopub.status.busy": "2025-11-11T06:03:16.940571Z",
     "iopub.status.idle": "2025-11-11T06:03:35.821559Z",
     "shell.execute_reply": "2025-11-11T06:03:35.820448Z",
     "shell.execute_reply.started": "2025-11-11T06:03:16.941093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+\n",
      "|rating|item_id|user_id|\n",
      "+------+-------+-------+\n",
      "|     0|      0|      0|\n",
      "+------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count nulls per column\n",
    "null_counts = df_spark_indexed.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_spark_indexed.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bfe0956-aca8-4659-a0b5-adcba5f2e00f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:03:35.823114Z",
     "iopub.status.busy": "2025-11-11T06:03:35.822734Z",
     "iopub.status.idle": "2025-11-11T06:03:35.831780Z",
     "shell.execute_reply": "2025-11-11T06:03:35.829965Z",
     "shell.execute_reply.started": "2025-11-11T06:03:35.823079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:/home2/bsdsba2027/rvelasco/BDCC Labs/BDCC_Lab1/als_spark_checkpoints/4a848607-cc8a-4c22-a48d-f022637b1063\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext.getCheckpointDir())  # checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3650a1a7-d611-4738-8a41-3806e6c1fa43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:03:35.834655Z",
     "iopub.status.busy": "2025-11-11T06:03:35.833613Z",
     "iopub.status.idle": "2025-11-11T06:06:22.785894Z",
     "shell.execute_reply": "2025-11-11T06:06:22.784849Z",
     "shell.execute_reply.started": "2025-11-11T06:03:35.834595Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train an ALS model\n",
    "train, test = df_spark_indexed.randomSplit([0.8, 0.2])\n",
    "als = ALS(rank=2, maxIter=5, \n",
    "          userCol=\"user_id\", itemCol='item_id', \n",
    "          ratingCol=\"rating\", coldStartStrategy='drop',\n",
    "          checkpointInterval=10  # Saves to disk after n iterations\n",
    "         )\n",
    "als_model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef5a06e0-a970-4c9d-adda-c17fabbbdf9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:06:22.790515Z",
     "iopub.status.busy": "2025-11-11T06:06:22.789658Z",
     "iopub.status.idle": "2025-11-11T06:07:24.767145Z",
     "shell.execute_reply": "2025-11-11T06:07:24.765721Z",
     "shell.execute_reply.started": "2025-11-11T06:06:22.790455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error:1.2393715582711229\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = als_model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error:\" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13dfd45b-a0a9-4593-a9b0-d815384223c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:07:24.769504Z",
     "iopub.status.busy": "2025-11-11T06:07:24.768938Z",
     "iopub.status.idle": "2025-11-11T06:09:58.037635Z",
     "shell.execute_reply": "2025-11-11T06:09:58.035809Z",
     "shell.execute_reply.started": "2025-11-11T06:07:24.769450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building evaluation dataset...\n",
      "✓ Evaluation dataset ready\n",
      "Sampling 0.5% of users...\n",
      "Sample size: 1,363 users\n",
      "Evaluating NDCG...\n",
      "\n",
      "==================================================\n",
      "NDCG at k=3: 0.000434\n",
      "==================================================\n",
      "\n",
      "Array size check:\n",
      "+-------+------------------+---------+\n",
      "|summary|       actual_size|pred_size|\n",
      "+-------+------------------+---------+\n",
      "|  count|              1363|     1363|\n",
      "|   mean| 8.268525311812178|     10.0|\n",
      "| stddev|7.1065790151099115|      0.0|\n",
      "|    min|                 1|       10|\n",
      "|    max|                20|       10|\n",
      "+-------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list, col, size, slice\n",
    "from pyspark.ml.evaluation import RankingEvaluator\n",
    "\n",
    "print(\"Building evaluation dataset...\")\n",
    "\n",
    "# Get top-10 recommendations\n",
    "k = 10\n",
    "userRecs = als_model.recommendForAllUsers(k)\n",
    "\n",
    "dfs_preds_grouped = userRecs.select(\n",
    "    col('user_id'),\n",
    "    col('recommendations.item_id').alias('predicted_item_id_arr')\n",
    ").withColumn(\n",
    "    'predicted_item_id_arr',\n",
    "    col('predicted_item_id_arr').cast('array<double>')\n",
    ")\n",
    "\n",
    "# Get actual highly-rated items from test\n",
    "thresh = 4.0\n",
    "test_thresh_grouped = test.filter(\n",
    "    col('rating') >= thresh\n",
    ").groupBy('user_id').agg(\n",
    "    collect_list(col('item_id').cast('double')).alias('rated_item_id_arr')\n",
    ")\n",
    "\n",
    "# Join predictions with actuals\n",
    "dfs_preds_thresh_for_eval = test_thresh_grouped.join(\n",
    "    dfs_preds_grouped,\n",
    "    on='user_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# CRITICAL: Limit array sizes to reduce computation\n",
    "dfs_preds_limited = dfs_preds_thresh_for_eval.withColumn(\n",
    "    'rated_item_id_arr',\n",
    "    slice('rated_item_id_arr', 1, 20)  # Max 20 items\n",
    ").withColumn(\n",
    "    'predicted_item_id_arr',\n",
    "    slice('predicted_item_id_arr', 1, 10)  # Max 10 predictions\n",
    ")\n",
    "\n",
    "print(\"✓ Evaluation dataset ready\")\n",
    "\n",
    "# Sample VERY small first - only 0.5%\n",
    "print(\"Sampling 0.5% of users...\")\n",
    "dfs_preds_sampled = dfs_preds_limited.sample(fraction=0.005, seed=42)\n",
    "dfs_preds_sampled.cache()\n",
    "\n",
    "sample_count = dfs_preds_sampled.count()\n",
    "print(f\"Sample size: {sample_count:,} users\")\n",
    "\n",
    "if sample_count > 0:\n",
    "    # Evaluate\n",
    "    evaluator = RankingEvaluator(\n",
    "        labelCol='rated_item_id_arr',\n",
    "        predictionCol='predicted_item_id_arr',\n",
    "        metricName='ndcgAtK',\n",
    "        k=3\n",
    "    )\n",
    "    \n",
    "    print(\"Evaluating NDCG...\")\n",
    "    ndcg_k = evaluator.evaluate(dfs_preds_sampled)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"NDCG at k=3: {ndcg_k:.6f}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Quick diagnostics\n",
    "    print(\"\\nArray size check:\")\n",
    "    dfs_preds_sampled.select(\n",
    "        size('rated_item_id_arr').alias('actual_size'),\n",
    "        size('predicted_item_id_arr').alias('pred_size')\n",
    "    ).describe().show()\n",
    "else:\n",
    "    print(\"ERROR: Sample is empty!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4e57e-ee1a-40f5-a349-541b087698a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5bfd3-837e-467c-b323-cd9aaa8dd117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
