{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f01185-3744-40aa-a125-7288504a5de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T12:46:06.683918Z",
     "iopub.status.busy": "2025-11-12T12:46:06.683220Z",
     "iopub.status.idle": "2025-11-12T12:46:10.104119Z",
     "shell.execute_reply": "2025-11-12T12:46:10.102768Z",
     "shell.execute_reply.started": "2025-11-12T12:46:06.683859Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, RankingEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "560032f5-5b1a-4951-bced-bb25014be8a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T12:46:10.105978Z",
     "iopub.status.busy": "2025-11-12T12:46:10.105572Z",
     "iopub.status.idle": "2025-11-12T12:46:16.382093Z",
     "shell.execute_reply": "2025-11-12T12:46:16.379938Z",
     "shell.execute_reply.started": "2025-11-12T12:46:10.105957Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "     .builder\n",
    "     .master('local[*]') # tells you master is 1 laptop using all 4 executors\n",
    "     .config(\"spark.driver.memory\", \"8g\")\n",
    "     .config(\"spark.executor.memory\", \"8g\")\n",
    "     .config(\"spark.sql.shuffle.partitions\", \"8\")  # reduce for local\n",
    "     .getOrCreate()) # make new or get latest session\n",
    "\n",
    "spark.sparkContext.setCheckpointDir(\"./als_spark_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91af199-9145-4e22-bcc6-ea0fad56df3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T12:46:16.385610Z",
     "iopub.status.busy": "2025-11-12T12:46:16.384944Z",
     "iopub.status.idle": "2025-11-12T12:46:23.051222Z",
     "shell.execute_reply": "2025-11-12T12:46:23.049541Z",
     "shell.execute_reply.started": "2025-11-12T12:46:16.385541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews 6166422\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./df_spark_indexed.parquet\"\n",
    "\n",
    "# Check if folder exists\n",
    "if not os.path.exists(folder_path):\n",
    "    # Read board game geek file on spark\n",
    "    schema = \"\"\"\n",
    "    _c0 INT,\n",
    "    user STRING,\n",
    "    rating FLOAT,\n",
    "    comment STRING,\n",
    "    id INT, \n",
    "    name STRING\n",
    "    \"\"\"\n",
    "    # Fix quote handling for comments column \n",
    "    df_spark = spark.read.csv(\n",
    "        \"/mnt/data/public/bgg/bgg-19m-reviews.csv\",\n",
    "        sep=',', header=True,\n",
    "        schema=schema,\n",
    "        multiLine=True,\n",
    "        quote='\"',\n",
    "        escape='\"')\n",
    "    df_spark = df_spark.drop(\"_c0\", \"comment\", \"name\")\n",
    "\n",
    "    # Get top 500 games by reviews\n",
    "    df_top_items = (\n",
    "        df_spark.groupby(\"ID\")\n",
    "        .count()    \n",
    "        .orderBy(F.desc(\"count\"))\n",
    "        .limit(500)\n",
    "    )\n",
    "    \n",
    "    # Filter to top 500 games first\n",
    "    df_filter = df_spark.join(\n",
    "        df_top_items.select(\"ID\"), \n",
    "        on=\"ID\", \n",
    "        how=\"inner\"\n",
    "    )\n",
    "    \n",
    "    # Get users who reviewed more than 44 games (within top 500)\n",
    "    df_active_users = (\n",
    "        df_filter.groupby(\"user\")\n",
    "        .count()\n",
    "        .filter(F.col(\"count\") > 44)\n",
    "    )\n",
    "    \n",
    "    # Filter to only active users\n",
    "    df_filter2 = df_filter.join(\n",
    "        df_active_users.select(\"user\"), \n",
    "        on=\"user\", \n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # Map user name to integer\n",
    "    user_indexer = StringIndexer(inputCol=\"user\", outputCol=\"user_id\")\n",
    "    df_spark_indexed = user_indexer.fit(df_filter2).transform(df_filter2)\n",
    "    \n",
    "    # Save Spark DF mapping of user to User ID\n",
    "    user_mapping = df_spark_indexed.select(\"user\", \"user_id\").distinct()\n",
    "    df_spark_indexed = df_spark_indexed.drop(\"user\")\n",
    "    \n",
    "    # Change item column name for unformity\n",
    "    df_spark_indexed = df_spark_indexed.withColumnRenamed(\"id\", \"item_id\")\n",
    "    \n",
    "    (df_spark_indexed\n",
    "     .write\n",
    "     .parquet(\"df_spark_indexed.parquet\"))\n",
    "\n",
    "df_spark_indexed = spark.read.parquet(folder_path)\n",
    "print(f\"Number of reviews {df_spark_indexed.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb940c-1365-4705-92d6-a7ef930b3ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T12:46:23.053578Z",
     "iopub.status.busy": "2025-11-12T12:46:23.052967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with grid search...\n"
     ]
    }
   ],
   "source": [
    "train, test = df_spark_indexed.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Create ALS instance\n",
    "als = ALS(\n",
    "    userCol='user_id', \n",
    "    itemCol='item_id', \n",
    "    ratingCol='rating', \n",
    "    coldStartStrategy='drop',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Build parameter grid with BOTH regParam and rank\n",
    "param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(als.regParam, [.01, .005, .001])\\\n",
    "    .addGrid(als.rank, [2, 4, 6])\\\n",
    "    .build()\n",
    "\n",
    "# Cross validation\n",
    "cv = CrossValidator(\n",
    "    estimator=als, \n",
    "    estimatorParamMaps=param_grid, \n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Fit and evaluate\n",
    "print(\"Training with grid search...\")\n",
    "tuned_model = cv.fit(train)\n",
    "predictions = tuned_model.transform(test)\n",
    "\n",
    "# Evaluate RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "# Get best parameters\n",
    "best_rank = tuned_model.bestModel.rank\n",
    "best_reg = tuned_model.bestModel._java_obj.parent().getRegParam()\n",
    "\n",
    "print(f\"Best regParam: {best_reg}\")\n",
    "print(f\"Best rank: {best_rank}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67cfcf-457a-4c2e-9d2f-78b1c84a5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuned_model.bestModel\n",
    "best_model.save(\"als_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73cdf22-4d7b-4f49-bb77-76e0a0c51910",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "# get predicted ids per user\n",
    "pred = (best_model.recommendForAllUsers(k)\n",
    "    .select(\n",
    "    F.col(\"user_id\"),\n",
    "    F.col(\"recommendations.item_id\").alias(\"pred_array\")\n",
    "    ).withColumn(\"pred_array\",\n",
    "                 F.col(\"pred_array\").cast(\"array<double>\")\n",
    "                )\n",
    "       )\n",
    "\n",
    "# Add rank per user based on rating descending\n",
    "window = Window.partitionBy(\"user_id\").orderBy(F.desc(\"rating\"))\n",
    "\n",
    "actual = (test.withColumn(\"rank\", F.row_number().over(window))\n",
    "          .filter(F.col(\"rank\") <= k)\n",
    "          .groupBy(\"user_id\")\n",
    "          .agg(F.collect_list(\"item_id\").alias(\"actual_array\"))\n",
    "          .withColumn(\"actual_array\",\n",
    "                 F.col(\"actual_array\").cast(\"array<double>\")\n",
    "                )\n",
    "         )\n",
    "\n",
    "df_ndcg = pred.join(actual, on = 'user_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079405ff-71e7-4dea-9d95-0687e19f1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ndcg.limit(3).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10676095-8f54-4a68-8b9b-17eb38d13667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NDGC@K=3\n",
    "evaluator = RankingEvaluator(\n",
    "    labelCol='actual_array',\n",
    "    predictionCol='pred_array',\n",
    "    metricName='ndcgAtK',\n",
    "    k=3\n",
    ")\n",
    "\n",
    "ndcg_k = evaluator.evaluate(df_ndcg)\n",
    "print(f\"NDCG at k=3: {ndcg_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6252cb-5f94-4d62-a84a-9d977a95bb93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
